{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2321a4e0-0f43-4a62-a0ff-f046e0123593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot\n",
    "from torch.linalg import vector_norm as vnorm\n",
    "from torch.linalg import solve as solve_matrix_system\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "from telegramBot import Terminator\n",
    "\n",
    "num_cores = 8\n",
    "torch.set_num_interop_threads(num_cores) # Inter-op parallelism\n",
    "torch.set_num_threads(num_cores) # Intra-op parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7cd5c-a0f0-4669-9c5c-4066cfafa41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class prova(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer0 = nn.Linear(4, 12)\n",
    "        self.layer1 = nn.Linear(12, 2)\n",
    "        self.layer2 = nn.Linear(12, 4)\n",
    "        self.layer2_1 = nn.Linear(12, 4)\n",
    "        self.layer3 = nn.Linear(12, 4)\n",
    "        self.layer3_1 = nn.Linear(12, 4)\n",
    "\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr = 1e-3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.layer0(x)\n",
    "        z = F.relu(z)\n",
    "        o1 = self.layer1(z)\n",
    "        prj2, ort2, prj3, ort3 = self.project(z)\n",
    "        o2 = self.layer2(ort2) + self.layer2_1(prj2) \n",
    "        o3 = self.layer3(ort3) + self.layer3_1(prj3)\n",
    "\n",
    "        return o1, o2, o3\n",
    "\n",
    "    \n",
    "    # Assumption: W is column full rank. \n",
    "    def project(self, z): #https://math.stackexchange.com/questions/4021915/projection-orthogonal-to-two-vectors\n",
    "\n",
    "        W1 = self.layer1.weight.clone().detach()\n",
    "        W2 = self.layer2.weight.clone().detach()\n",
    "        ort2 = torch.empty_like(z)\n",
    "        ort3 = torch.empty_like(z)\n",
    "\n",
    "        for i, zi in enumerate(z):\n",
    "            Rk = torch.diag(torch.where(zi.clone().detach() != 0, 1.0, 0.0))\n",
    "            W1k = W1.mm(Rk)\n",
    "            W2k_ = W2.mm(Rk)\n",
    "            W2k = torch.vstack((W1k, W2k_))\n",
    "            ort2[i,:] = self.compute_othogonal(zi, W1k)\n",
    "            ort3[i,:] = self.compute_othogonal(zi, W2k)\n",
    "            \n",
    "        prj2 = z.clone().detach() - ort2.clone().detach()\n",
    "        prj3 = z.clone().detach() - ort3.clone().detach()\n",
    "        \n",
    "        return prj2, ort2, prj3, ort3\n",
    "\n",
    "    def compute_othogonal(self, z, W, eps = 1e-8):\n",
    "        WWT = torch.matmul(W, W.T)\n",
    "        P = solve_matrix_system(WWT + torch.randn_like(WWT) * eps, torch.eye(W.size(0)))\n",
    "        P = torch.matmul(P, W)\n",
    "        P = torch.eye(W.size(1)) - torch.matmul(W.T, P)\n",
    "        \n",
    "        return torch.matmul(z, P)\n",
    "\n",
    "    def print_forward(self, x):\n",
    "        o1, o2, o3 = self.forward(x)\n",
    "        print(o1, end = \"\\n\\n\")\n",
    "        print(o2, end = \"\\n\\n\")\n",
    "        print(o3, end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a63403-bc4b-47da-b937-4b652a7951c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = prova()\n",
    "x = torch.rand(2, 4)\n",
    "u = p(x)\n",
    "y = torch.rand(2,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17038827-a4b2-43ad-abd2-382f4dd90edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dot(p(x), params=dict(list(p.named_parameters()))).render(\"../imgs/hcnn3_torchviz\", format=\"png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29655586-4aae-4331-8ca5-1a45a639ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = p(x)\n",
    "p.optimizer.zero_grad()\n",
    "loss2 = p.criterion(u[1], y)\n",
    "loss2.backward()\n",
    "p.optimizer.step()\n",
    "p(x)[0]-u[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ab7ee9-e3f8-4dd2-a45d-1636cb9137e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "uu = p(x)\n",
    "p.optimizer.zero_grad()\n",
    "loss3 = p.criterion(uu[2], y)\n",
    "loss3.backward()\n",
    "print(p.layer2.weight.grad)\n",
    "p.optimizer.step()\n",
    "print(p(x)[0]-uu[0])\n",
    "print(p(x)[1]-uu[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
