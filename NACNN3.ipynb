{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb813a5-158b-4145-8813-e704911038bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from abc import ABC\n",
    "\n",
    "num_cores = 8\n",
    "torch.set_num_interop_threads(num_cores) # Inter-op parallelism\n",
    "torch.set_num_threads(num_cores) # Intra-op parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3042e2eb-e323-4f2e-98b3-476816779a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c3_to_c1(y):\n",
    "    if y < 2 or y > 7:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def c3_to_c2(y):\n",
    "    match y:\n",
    "        case 0:\n",
    "            return 0\n",
    "        case 1:\n",
    "            return 2\n",
    "        case 2:\n",
    "            return 3\n",
    "        case 3:\n",
    "            return 5\n",
    "        case 4:\n",
    "            return 6\n",
    "        case 5:\n",
    "            return 5\n",
    "        case 6:\n",
    "            return 4\n",
    "        case 7:\n",
    "            return 6\n",
    "        case 8:\n",
    "            return 1\n",
    "        case _:\n",
    "            return 2\n",
    "\n",
    "def c2_to_c1(y):\n",
    "    if y < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc309aa-705a-4d04-844c-c0705228089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "coarser = Lambda(lambda y: torch.tensor([c3_to_c1(y), c3_to_c2(y), int(y)]))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_cores)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0ea53-ba3c-4e1e-b687-d361ce7c7c6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NA_Layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52da67f-ad0f-4bf4-a9dc-9be1bc0a4441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class NA_Layer2(ABC, nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n\\n    def forward(self, x):\\n        yf = self.layer_f(x[0, :])\\n        yi = self.layer_f(x[1, :]) + self.layer_i(x[0, :])\\n\\n        return torch.stack((yf, yi))\\n\\n    def infinitesimal_gradient(self):\\n        self.layer_i.weight.grad = self.layer_f.weight.grad\\n        self.layer_f.weight.grad = None\\n\\n        if bias:\\n            self.layer_i.bias.grad = self.layer_f.bias.grad\\n            self.layer_f.bias.grad = None\\n\\nclass NA_Linear2(NA_Layer2):\\n    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\\n\\n        super().__init__()\\n        self.bias = bias\\n        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\\n        self.layer_i = nn.Linear(in_features, out_features, bias, device, dtype)\\n\\nclass NA_Conv2d2(NA_Layer2):\\n\\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \\n                padding_mode='zeros', device=None, dtype=None):\\n\\n        super().__init__()\\n        self.bias = bias\\n        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \\n                padding_mode, device, dtype)\\n        self.layer_i = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \\n                padding_mode, device, dtype)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class NA_Layer2(ABC, nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi = self.layer_f(x[1, :]) + self.layer_i(x[0, :])\n",
    "\n",
    "        return torch.stack((yf, yi))\n",
    "\n",
    "    def infinitesimal_gradient(self):\n",
    "        self.layer_i.weight.grad = self.layer_f.weight.grad\n",
    "        self.layer_f.weight.grad = None\n",
    "\n",
    "        if bias:\n",
    "            self.layer_i.bias.grad = self.layer_f.bias.grad\n",
    "            self.layer_f.bias.grad = None\n",
    "\n",
    "class NA_Linear2(NA_Layer2):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "\n",
    "class NA_Conv2d2(NA_Layer2):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                padding_mode='zeros', device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e30205-5405-4cd6-9c8d-4dfc2b1fc36e",
   "metadata": {},
   "source": [
    "## NA_Layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "773740a6-edb6-4c6c-b808-ae622e9a2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NA_Layer(ABC, nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class NA_combiner3(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi1 = self.layer_f(x[1, :]) + self.layer_i1(x[0, :])\n",
    "        yi2 = self.layer_f(x[2, :]) + self.layer_i1(x[1, :]) + self.layer_i2(x[0, :])\n",
    "\n",
    "        return torch.stack((yf, yi1, yi2))\n",
    "\n",
    "    def infinitesimal_gradient(self, i):\n",
    "        if i == 1:\n",
    "            self.layer_i1.weight.grad = self.layer_f.weight.grad\n",
    "            self.layer_f.weight.grad = None\n",
    "    \n",
    "            if bias:\n",
    "                self.layer_i1.bias.grad = self.layer_f.bias.grad\n",
    "                self.layer_f.bias.grad = None\n",
    "        \n",
    "        elif i == 2:\n",
    "            self.layer_i2.weight.grad = self.layer_f.weight.grad\n",
    "            self.layer_i1.weight.grad = None\n",
    "            self.layer_f.weight.grad = None\n",
    "    \n",
    "            if bias:\n",
    "                self.layer_i2.bias.grad = self.layer_f.bias.grad\n",
    "                self.layer_i1.bias.grad = None\n",
    "                self.layer_f.bias.grad = None\n",
    "            \n",
    "class NA_separate3(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi1 = self.layer_i1(x[1, :])\n",
    "        yi2 = self.layer_i2(x[2, :])\n",
    "\n",
    "        return torch.stack((yf, yi1, yi2))\n",
    "\n",
    "class NA_independent(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        for i in np.arange(x.size(0)):\n",
    "            y.append(self.layer(x[i, :]))\n",
    "\n",
    "        return torch.stack(y)\n",
    "\n",
    "class NA_Linear3(NA_combiner3):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i1 = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i2 = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "\n",
    "class NA_Conv2d3(NA_combiner3):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                padding_mode='zeros', device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "\n",
    "class NA_BatchNorm2d3(NA_separate3):\n",
    "\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5, momentum: float = 0.1, affine: bool = True,\n",
    "                 track_running_stats: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layer_f = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i1 = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i2 = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "\n",
    "class NA_BatchNorm1d3(NA_separate3):\n",
    "\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5, momentum: float = 0.1, affine: bool = True,\n",
    "                 track_running_stats: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layer_f = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i1 = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i2 = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "\n",
    "class NA_MaxPool2d(NA_independent):\n",
    "\n",
    "    def __init__(self, kernel_size, stride = None, padding = 0, dilation = 1, return_indices = False, ceil_mode = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layer = nn.MaxPool2d(kernel_size, stride, padding, dilation, return_indices, ceil_mode)\n",
    "\n",
    "class NA_Dropout(NA_independent):\n",
    "\n",
    "     def __init__(self, p: float = 0.5, inplace: bool = False):\n",
    "         \n",
    "         super().__init__()\n",
    "         self.layer = nn.Dropout(p, inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bee2f1c-fe02-4497-8102-4fbbcdceff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NA_BCNN3(nn.Module):\n",
    "    def __init__(self, learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, \n",
    "                 every_print = 512, training_size = 50000):\n",
    "\n",
    "        super().__init__()\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.activation = F.relu\n",
    "        self.class_levels = 3\n",
    "        self.max_children = 4\n",
    "        self.num_c_1 = num_class_c1\n",
    "        self.num_c_2 = num_class_c2\n",
    "        self.num_c_3 = num_class_c3\n",
    "        self.epochs = epochs\n",
    "        self.labels_c_1 = labels_c_1\n",
    "        self.labels_c_2 = labels_c_2\n",
    "        self.labels_c_3 = labels_c_3\n",
    "        self.every_print = every_print - 1 # assumed power of 2, -1 to make the mask\n",
    "        self.track_size = int( training_size / batch_size / every_print ) \n",
    "\n",
    "        self.layer1  = NA_Conv2d3(3, 64, (3,3), padding = 'same')\n",
    "        self.layer2  = NA_BatchNorm2d3(64)\n",
    "        self.layer3  = NA_Conv2d3(64, 64, (3,3), padding = 'same')\n",
    "        self.layer4  = NA_BatchNorm2d3(64)\n",
    "        self.layer5  = NA_MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layer6  = NA_Conv2d3(64, 128, (3,3), padding = 'same')\n",
    "        self.layer7  = NA_BatchNorm2d3(128)\n",
    "        self.layer8  = NA_Conv2d3(128, 128, (3,3), padding = 'same')\n",
    "        self.layer9  = NA_BatchNorm2d3(128)\n",
    "        self.layer10 = NA_MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layerb11 = NA_Linear3(8*8*128, 256)\n",
    "        self.layerb12 = NA_BatchNorm1d3(256)\n",
    "        self.layerb13 = NA_Dropout(0.5)\n",
    "        self.layerb14 = NA_Linear3(256, 256)\n",
    "        self.layerb15 = NA_BatchNorm1d3(256)\n",
    "        self.layerb16 = NA_Dropout(0.5)\n",
    "        self.layerb17 = NA_Linear3(256, self.max_children)\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[0], \n",
    "                                   momentum = self.momentum, nesterov = self.nesterov)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1\n",
    "        z = self.layer1(x)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer4(z)\n",
    "        z = self.layer5(z)\n",
    "\n",
    "        # block 2\n",
    "        z = self.layer6(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer7(z)\n",
    "        z = self.layer8(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer9(z)\n",
    "        z = self.layer10(z)\n",
    "\n",
    "        # branch 1\n",
    "        b1 = torch.flatten(z, start_dim = 2)\n",
    "        b1 = self.layerb11(b1)\n",
    "        b1 = self.activation(b1)\n",
    "        b1 = self.layerb12(b1)\n",
    "        b1 = self.layerb13(b1)\n",
    "        b1 = self.layerb14(b1)\n",
    "        b1 = self.activation(b1)\n",
    "        b1 = self.layerb15(b1)\n",
    "        b1 = self.layerb16(b1)\n",
    "        b1 = self.layerb17(b1)\n",
    "\n",
    "        return b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb179173-4f1e-4e66-8f7e-8f2d51521a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [3e-3, 5e-4, 1e-4]\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "epochs = 60\n",
    "num_class_c1 = 2\n",
    "num_class_c2 = 7\n",
    "num_class_c3 = 10\n",
    "every_print = 32\n",
    "\n",
    "#--- coarse 1 classes ---\n",
    "labels_c_1 = ('transport', 'animal')\n",
    "#--- coarse 2 classes ---\n",
    "labels_c_2 = ('sky', 'water', 'road', 'bird', 'reptile', 'pet', 'medium')\n",
    "#--- fine classes ---\n",
    "labels_c_3 = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "215b19b0-4888-441a-aaf4-a42fcbb8e4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, _ = next(iter(testloader))\n",
    "img = torch.stack((img, torch.zeros_like(img), torch.zeros_like(img)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b8cb713-b124-4ccd-9748-467b99c72839",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = NA_BCNN3(learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, every_print)\n",
    "\n",
    "z = cnn(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9fb053e9-4cbb-4fc5-8ef8-84d3c1593ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 128, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6af62e-ff44-4b64-bad5-8f72411ef1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
