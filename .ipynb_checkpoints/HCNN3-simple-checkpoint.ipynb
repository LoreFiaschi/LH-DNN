{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb29cf94-a6b3-4ef7-a8be-cec4752524d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchviz import make_dot\n",
    "from torch.linalg import vector_norm as vnorm\n",
    "from torch.linalg import solve as solve_matrix_system\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "\n",
    "from telegramBot import Terminator\n",
    "\n",
    "num_cores = 8\n",
    "torch.set_num_interop_threads(num_cores) # Inter-op parallelism\n",
    "torch.set_num_threads(num_cores) # Intra-op parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf44cb0-e765-46f0-badd-397e8a2aaf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c3_to_c1(y):\n",
    "    if y < 2 or y > 7:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def c3_to_c2(y):\n",
    "    match y:\n",
    "        case 0:\n",
    "            return 0\n",
    "        case 1:\n",
    "            return 2\n",
    "        case 2:\n",
    "            return 3\n",
    "        case 3:\n",
    "            return 5\n",
    "        case 4:\n",
    "            return 6\n",
    "        case 5:\n",
    "            return 5\n",
    "        case 6:\n",
    "            return 4\n",
    "        case 7:\n",
    "            return 6\n",
    "        case 8:\n",
    "            return 1\n",
    "        case _:\n",
    "            return 2\n",
    "\n",
    "def c2_to_c1(y):\n",
    "    if y < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "378fc441-1f9c-4486-9414-9a770c81bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "coarser = Lambda(lambda y: torch.tensor([c3_to_c1(y), c3_to_c2(y), int(y)]))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_cores)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_cores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca54ed2-9829-46d4-aebd-c08860c9203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HCNN3(nn.Module):\n",
    "    def __init__(self, learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, \n",
    "                 every_print = 512, training_size = 50000):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.activation = F.relu\n",
    "        self.class_levels = 3\n",
    "        self.num_c_1 = num_class_c1\n",
    "        self.num_c_2 = num_class_c2\n",
    "        self.num_c_3 = num_class_c3\n",
    "        self.epochs = epochs\n",
    "        self.labels_c_1 = labels_c_1\n",
    "        self.labels_c_2 = labels_c_2\n",
    "        self.labels_c_3 = labels_c_3\n",
    "        self.every_print = every_print - 1 # assumed power of 2, -1 to make the mask\n",
    "        self.track_size = int( training_size / batch_size / every_print ) \n",
    "\n",
    "        self.layer1  = nn.Conv2d(3, 64, (3,3), padding = 'same')\n",
    "        self.layer2  = nn.BatchNorm2d(64)\n",
    "        self.layer3  = nn.Conv2d(64, 64, (3,3), padding = 'same')\n",
    "        self.layer4  = nn.BatchNorm2d(64)\n",
    "        self.layer5  = nn.MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layer6  = nn.Conv2d(64, 128, (3,3), padding = 'same')\n",
    "        self.layer7  = nn.BatchNorm2d(128)\n",
    "        self.layer8  = nn.Conv2d(128, 128, (3,3), padding = 'same')\n",
    "        self.layer9  = nn.BatchNorm2d(128)\n",
    "        self.layer10 = nn.MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layerb11 = nn.Linear(8*8*128, 256)\n",
    "        self.layerb12 = nn.BatchNorm1d(256)\n",
    "        self.layerb13 = nn.Dropout(0.5)\n",
    "        self.layerb14 = nn.Linear(256, 256)\n",
    "        self.layerb15 = nn.BatchNorm1d(256)\n",
    "        self.layerb16 = nn.Dropout(0.5)\n",
    "        self.layerb_mid = nn.Linear(256, 256)\n",
    "        self.layerb17 = nn.Linear(256, self.num_c_1)\n",
    "        \n",
    "        self.layerb27 = nn.Linear(256, self.num_c_2)\n",
    "        self.layerb27_ = nn.Linear(256, self.num_c_2)\n",
    "        \n",
    "        self.layerb37 = nn.Linear(256, self.num_c_3)\n",
    "        self.layerb37_ = nn.Linear(256, self.num_c_3)\n",
    "\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[0], \n",
    "                                   momentum = self.momentum, nesterov = self.nesterov)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1\n",
    "        z = self.layer1(x)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer4(z)\n",
    "        z = self.layer5(z)\n",
    "\n",
    "        # block 2\n",
    "        z = self.layer6(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer7(z)\n",
    "        z = self.layer8(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer9(z)\n",
    "        z = self.layer10(z)\n",
    "        z = torch.flatten(z, start_dim = 1)\n",
    "\n",
    "        # branch 1\n",
    "        z = self.layerb11(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layerb12(z)\n",
    "        z = self.layerb13(z)\n",
    "        z = self.layerb14(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layerb15(z)\n",
    "        z = self.layerb16(z)\n",
    "        z = self.layerb_mid(z)\n",
    "        z = self.activation(z)\n",
    "\n",
    "        # projections\n",
    "        prj2, ort2, prj3, ort3 = self.project(z)\n",
    "\n",
    "        #vbranch 1\n",
    "        b1 = self.layerb17(z)\n",
    "        \n",
    "        # branch 2\n",
    "        b2 = self.layerb27(ort2) + self.layerb27_(prj2)\n",
    "\n",
    "        # branch 3\n",
    "        b3 = self.layerb37(ort3) + self.layerb37_(prj3)\n",
    "\n",
    "        return b1, b2, b3\n",
    "\n",
    "    \n",
    "    # Assumption: W is column full rank. \n",
    "    def project(self, z): #https://math.stackexchange.com/questions/4021915/projection-orthogonal-to-two-vectors\n",
    "\n",
    "        W1 = self.layerb17.weight.clone().detach()\n",
    "        W2 = self.layerb27.weight.clone().detach()\n",
    "        ort2 = torch.empty_like(z)\n",
    "        ort3 = torch.empty_like(z)\n",
    "\n",
    "        for i, zi in enumerate(z):\n",
    "            Rk = torch.diag(torch.where(zi.clone().detach() != 0, 1.0, 0.0))\n",
    "            W1k = W1.mm(Rk)\n",
    "            W2k_ = W2.mm(Rk)\n",
    "            W2k = torch.vstack((W1k, W2k_))\n",
    "            ort2[i,:] = self.compute_othogonal(zi, W1k)\n",
    "            ort3[i,:] = self.compute_othogonal(zi, W2k)\n",
    "            \n",
    "        prj2 = z.clone().detach() - ort2.clone().detach()\n",
    "        prj3 = z.clone().detach() - ort3.clone().detach()\n",
    "        \n",
    "        return prj2, ort2, prj3, ort3\n",
    "\n",
    "    def compute_othogonal(self, z, W, eps = 1e-8):\n",
    "        WWT = torch.matmul(W, W.T)\n",
    "        P = solve_matrix_system(WWT + torch.randn_like(WWT) * eps, torch.eye(W.size(0)))\n",
    "        P = torch.matmul(P, W)\n",
    "        P = torch.eye(W.size(1)) - torch.matmul(W.T, P)\n",
    "        \n",
    "        return torch.matmul(z, P)\n",
    "\n",
    "    \n",
    "    def update_training_params(self, epoch):\n",
    "        if epoch == 41:\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[1], \n",
    "                               momentum = self.momentum, nesterov = self.nesterov)\n",
    "        elif epoch == 51:\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[2], \n",
    "                               momentum = self.momentum, nesterov = self.nesterov)\n",
    "\n",
    "\n",
    "    def predict_and_learn(self, batch, labels):\n",
    "        self.optimizer.zero_grad()\n",
    "        predict = self(batch)\n",
    "        loss_f = self.criterion(predict[0], labels[:,0])\n",
    "        loss_i1 = self.criterion(predict[1], labels[:,1])\n",
    "        loss_i2 = self.criterion(predict[2], labels[:,2])\n",
    "        \n",
    "        loss_f.backward(retain_graph=True)\n",
    "        loss_i1.backward(retain_graph=True)\n",
    "        loss_i2.backward()\n",
    "\n",
    "        self.optimizer.step()\n",
    "\n",
    "        return torch.tensor([loss_f, loss_i1, loss_i2])\n",
    "\n",
    "    \n",
    "    def train_model(self, verbose = False):\n",
    "        self.train()\n",
    "        \n",
    "        for epoch in np.arange(self.epochs):\n",
    "            self.update_training_params(epoch)\n",
    "\n",
    "            if verbose:\n",
    "                running_loss = torch.zeros(self.class_levels)\n",
    "            \n",
    "            for iter, (batch, labels) in enumerate(self.trainloader):\n",
    "                loss = self.predict_and_learn(batch, labels)\n",
    "\n",
    "                if verbose:\n",
    "                    running_loss += (loss - running_loss) / (iter+1)\n",
    "                    if (iter + 1) & self.every_print == 0:\n",
    "                        print(f'[{epoch + 1}] loss_f : {running_loss[0] :.3f}')\n",
    "                        print(f'[{epoch + 1}] loss_i1: {running_loss_[1] :.3f}')\n",
    "                        print(f'[{epoch + 1}] loss_i2: {running_loss_[2] :.3f}')\n",
    "                        for i in np.arange(self.class_levels):\n",
    "                            running_loss[i] = 0.0\n",
    "\n",
    "    \n",
    "    def train_track(self, filename = \"\"):\n",
    "        self.train()\n",
    "        \n",
    "        self.loss_track = torch.zeros(self.epochs * self.track_size, self.class_levels)\n",
    "        self.accuracy_track = torch.zeros(self.epochs * self.track_size, self.class_levels)\n",
    "        num_push = 0\n",
    "        \n",
    "        for epoch in np.arange(self.epochs):\n",
    "            print(epoch)\n",
    "            self.update_training_params(epoch)\n",
    "\n",
    "            running_loss = torch.zeros(self.class_levels)\n",
    "            \n",
    "            for iter, (batch, labels) in enumerate(self.trainloader):\n",
    "                loss = self.predict_and_learn(batch, labels)\n",
    "\n",
    "                running_loss += (loss - running_loss) / (iter+1)\n",
    "                if (iter + 1) & self.every_print == 0:\n",
    "                    self.loss_track[num_push, :] = running_loss\n",
    "                    self.accuracy_track[num_push, :] = self.test(mode = \"train\")\n",
    "                    num_push += 1\n",
    "                    for i in np.arange(self.class_levels):\n",
    "                            running_loss[i] = 0.0\n",
    "\n",
    "        self.plot_training_loss(filename+\"_train_loss.pdf\")\n",
    "        self.plot_test_accuracy(filename+\"_test_accuracy_.pdf\")\n",
    "\n",
    "    \n",
    "    def initialize_memory(self):\n",
    "        self.correct_c1_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_pred = torch.zeros_like(self.correct_c1_pred)\n",
    "        \n",
    "        self.correct_c2_pred = torch.zeros(self.num_c_2)\n",
    "        self.total_c2_pred = torch.zeros_like(self.correct_c2_pred)\n",
    "        \n",
    "        self.correct_c3_pred = torch.zeros(self.num_c_3)\n",
    "        self.total_c3_pred = torch.zeros_like(self.correct_c3_pred)\n",
    "\n",
    "        self.correct_c1_vs_c2_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_vs_c2_pred = torch.zeros_like(self.correct_c1_vs_c2_pred)\n",
    "\n",
    "        self.correct_c2_vs_c3_pred = torch.zeros(self.num_c_2)\n",
    "        self.total_c2_vs_c3_pred = torch.zeros_like(self.correct_c2_vs_c3_pred)\n",
    "\n",
    "        self.correct_c1_vs_c3_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_vs_c3_pred = torch.zeros_like(self.correct_c1_vs_c3_pred)\n",
    "\n",
    "    \n",
    "    def collect_test_performance(self):\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.testloader:\n",
    "                predictions = self(images)\n",
    "                predicted = torch.zeros(predictions[0].size(0), self.class_levels, dtype=torch.long)\n",
    "                _, predicted[:,0] = torch.max(predictions[0], 1)\n",
    "                _, predicted[:,1] = torch.max(predictions[1], 1)\n",
    "                _, predicted[:,2] = torch.max(predictions[2], 1)\n",
    "\n",
    "                for i in np.arange(predictions[0].size(0)):\n",
    "                    if labels[i,0] == predicted[i,0]:\n",
    "                        self.correct_c1_pred[labels[i,0]] += 1\n",
    "                        \n",
    "                    if labels[i,1] == predicted[i,1]:\n",
    "                        self.correct_c2_pred[labels[i,1]] += 1\n",
    "\n",
    "                    if labels[i,2] == predicted[i,2]:\n",
    "                        self.correct_c3_pred[labels[i,2]] += 1\n",
    "\n",
    "                    if predicted[i,1] == c3_to_c2(predicted[i,2]):\n",
    "                        self.correct_c2_vs_c3_pred[predicted[i,1]] += 1\n",
    "\n",
    "                    if predicted[i,0] == c3_to_c1(predicted[i,2]):\n",
    "                        self.correct_c1_vs_c3_pred[predicted[i,0]] += 1\n",
    "\n",
    "                    if predicted[i,0] == c2_to_c1(predicted[i,1]):\n",
    "                        self.correct_c1_vs_c2_pred[predicted[i,0]] += 1\n",
    "                        \n",
    "                    self.total_c1_pred[labels[i,0]] += 1\n",
    "                    self.total_c2_pred[labels[i,1]] += 1\n",
    "                    self.total_c3_pred[labels[i,2]] += 1\n",
    "                    self.total_c1_vs_c3_pred[predicted[i,0]] += 1\n",
    "                    self.total_c1_vs_c2_pred[predicted[i,0]] += 1\n",
    "                    self.total_c2_vs_c3_pred[predicted[i,1]] += 1\n",
    "                    \n",
    "\n",
    "    def print_test_results(self):\n",
    "        # print accuracy for each class\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1 = 100 * float(self.correct_c1_pred[i]) / self.total_c1_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_1[i]:5s}: {accuracy_c1:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2 = 100 * float(self.correct_c2_pred[i]) / self.total_c2_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_2[i]:5s}: {accuracy_c2:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_3):\n",
    "            accuracy_c3 = 100 * float(self.correct_c3_pred[i]) / self.total_c3_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_3[i]:5s}: {accuracy_c3:.2f} %')\n",
    "            \n",
    "        # print accuracy for the whole dataset\n",
    "        print(\"\")\n",
    "        print(f'Accuracy on c1: {100 * self.correct_c1_pred.sum() // self.total_c1_pred.sum()} %')\n",
    "        print(f'Accuracy on c2: {100 * self.correct_c2_pred.sum() // self.total_c2_pred.sum()} %')\n",
    "        print(f'Accuracy on c3: {100 * self.correct_c3_pred.sum() // self.total_c3_pred.sum()} %')\n",
    "\n",
    "        # print cross classes accuracy (tree)\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1_c2 = 100 * float(self.correct_c1_vs_c2_pred[i]) / self.total_c1_vs_c2_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_1[i]:5s} vs c2: {accuracy_c1_c2:.2f} %')\n",
    "        \n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2_c3 = 100 * float(self.correct_c2_vs_c3_pred[i]) / self.total_c2_vs_c3_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_2[i]:5s} vs c3: {accuracy_c2_c3:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1_c3 = 100 * float(self.correct_c1_vs_c3_pred[i]) / self.total_c1_vs_c3_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_1[i]:5s} vs c3: {accuracy_c1_c3:.2f} %')\n",
    "\n",
    "\n",
    "    def barplot(self, x, accuracy, labels, title):\n",
    "        plt.bar(x, accuracy, tick_label = labels)\n",
    "        plt.xlabel(\"Classes\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(title)\n",
    "        plt.show();\n",
    "\n",
    "    \n",
    "    def plot_test_results(self):\n",
    "        # accuracy for each class\n",
    "        accuracy_c1 = torch.empty(self.num_c_1)\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1[i] = float(self.correct_c1_pred[i]) / self.total_c1_pred[i]\n",
    "        self.barplot(np.arange(self.num_c_1), accuracy_c1, self.labels_c_1, \"Accuracy on the first level\")\n",
    "\n",
    "        accuracy_c2 = torch.empty(self.num_c_2 + 1)\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2[i] = float(self.correct_c2_pred[i]) / self.total_c2_pred[i]\n",
    "        accuracy_c2[self.num_c_2] = self.correct_c2_pred.sum() / self.total_c2_pred.sum()\n",
    "        self.barplot(np.arange(self.num_c_2 + 1), accuracy_c2, (*self.labels_c_2, 'overall'), \"Accuracy on the second level\")\n",
    "\n",
    "        accuracy_c3 = torch.empty(self.num_c_3 + 1)\n",
    "        for i in np.arange(self.num_c_3):\n",
    "            accuracy_c3[i] = float(self.correct_c3_pred[i]) / self.total_c3_pred[i]\n",
    "        accuracy_c3[self.num_c_3] = self.correct_c3_pred.sum() / self.total_c3_pred.sum()\n",
    "        self.barplot(np.arange(self.num_c_3 + 1), accuracy_c3, (*self.labels_c_3, 'overall'), \"Accuracy on the third level\")\n",
    "\n",
    "    \n",
    "    def test(self, mode = \"print\"):\n",
    "        self.initialize_memory()\n",
    "        self.eval()\n",
    "\n",
    "        self.collect_test_performance()\n",
    "\n",
    "        match mode:\n",
    "            case \"plot\":\n",
    "                self.plot_test_results()\n",
    "            case \"print\":\n",
    "                self.print_test_results()\n",
    "            case \"train\":\n",
    "                accuracy_c1 = self.correct_c1_pred.sum() / self.total_c1_pred.sum()\n",
    "                accuracy_c2 = self.correct_c2_pred.sum() / self.total_c2_pred.sum()\n",
    "                accuracy_c3 = self.correct_c3_pred.sum() / self.total_c3_pred.sum()\n",
    "\n",
    "                self.train()\n",
    "\n",
    "                return torch.tensor([accuracy_c1, accuracy_c2, accuracy_c3])\n",
    "            case _:\n",
    "                raise AttributeError(\"Test mode not available\")\n",
    "        \n",
    "    \n",
    "    def plot_training_loss(self, filename = None):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 0].numpy(), label = \"First level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 1].numpy(), label = \"Second level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 2].numpy(), label = \"Third level\")\n",
    "        plt.title(\"Training loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xticks(np.linspace(1, self.epochs, self.epochs)[0::2])\n",
    "        plt.legend()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show();\n",
    "\n",
    "    \n",
    "    def plot_test_accuracy(self, filename = None):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 0].numpy(), label = \"First level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 1].numpy(), label = \"Second level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 2].numpy(), label = \"Third level\")\n",
    "        plt.title(\"Test accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xticks(np.linspace(1, self.epochs, self.epochs)[0::2])\n",
    "        plt.legend()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show();\n",
    "\n",
    "    \n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    \n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a51e11-2d83-49ad-9c80-e244f7a17067",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [3e-3, 5e-4, 1e-4]\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "epochs = 60\n",
    "num_class_c1 = 2\n",
    "num_class_c2 = 7\n",
    "num_class_c3 = 10\n",
    "every_print = 32\n",
    "\n",
    "#--- coarse 1 classes ---\n",
    "labels_c_1 = ('transport', 'animal')\n",
    "#--- coarse 2 classes ---\n",
    "labels_c_2 = ('sky', 'water', 'road', 'bird', 'reptile', 'pet', 'medium')\n",
    "#--- fine classes ---\n",
    "labels_c_3 = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9986222-2e48-4679-9ec3-5869cfae7473",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Terminator()\n",
    "cnn = HCNN3(learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, every_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d5f6894-bbff-40fb-be0f-bcde450a8ced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/B-CNN3_CIFAR10_H\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mcnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     cnn\u001b[38;5;241m.\u001b[39msave_model(filename\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     cnn\u001b[38;5;241m.\u001b[39mtest(mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 196\u001b[0m, in \u001b[0;36mHCNN3.train_track\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    193\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_levels)\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m, (batch, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainloader):\n\u001b[0;32m--> 196\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_and_learn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (loss \u001b[38;5;241m-\u001b[39m running_loss) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;28miter\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevery_print \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[0;32mIn[4], line 153\u001b[0m, in \u001b[0;36mHCNN3.predict_and_learn\u001b[0;34m(self, batch, labels)\u001b[0m\n\u001b[1;32m    151\u001b[0m loss_f\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    152\u001b[0m loss_i1\u001b[38;5;241m.\u001b[39mbackward(retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 153\u001b[0m \u001b[43mloss_i2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor([loss_f, loss_i1, loss_i2])\n",
      "File \u001b[0;32m~/.virtualenvs/torch/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/torch/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cnn.train_model(verbose = False)\n",
    "err = False\n",
    "filename = \"models/B-CNN3_CIFAR10_H\"\n",
    "\n",
    "try:\n",
    "    cnn.train_track(filename)\n",
    "    cnn.save_model(filename+\".pt\")\n",
    "    cnn.test(mode = \"print\")\n",
    "    \n",
    "except Exception as errore:\n",
    "    err = errore\n",
    "\n",
    "if err is False:\n",
    "    bot.sendMessage(\"Programma terminato correttamente\")\n",
    "else:\n",
    "    bot.sendMessage(\"Programma NON terminato correttamente\\nTipo di errore: \"+err.__class__.__name__+\"\\nMessaggio: \"+str(err))\n",
    "    raise err"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
