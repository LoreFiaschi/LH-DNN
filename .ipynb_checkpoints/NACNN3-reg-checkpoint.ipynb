{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb813a5-158b-4145-8813-e704911038bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm \n",
    "from abc import ABC\n",
    "\n",
    "from telegramBot import Terminator\n",
    "\n",
    "num_cores = 8\n",
    "torch.set_num_interop_threads(num_cores) # Inter-op parallelism\n",
    "torch.set_num_threads(num_cores) # Intra-op parallelism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3042e2eb-e323-4f2e-98b3-476816779a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c3_to_c1(y):\n",
    "    if y < 2 or y > 7:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def c3_to_c2(y):\n",
    "    match y:\n",
    "        case 0:\n",
    "            return 0\n",
    "        case 1:\n",
    "            return 2\n",
    "        case 2:\n",
    "            return 3\n",
    "        case 3:\n",
    "            return 5\n",
    "        case 4:\n",
    "            return 6\n",
    "        case 5:\n",
    "            return 5\n",
    "        case 6:\n",
    "            return 4\n",
    "        case 7:\n",
    "            return 6\n",
    "        case 8:\n",
    "            return 1\n",
    "        case _:\n",
    "            return 2\n",
    "\n",
    "def c2_to_c1(y):\n",
    "    if y < 3:\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acc309aa-705a-4d04-844c-c0705228089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "coarser = Lambda(lambda y: torch.tensor([c3_to_c1(y), c3_to_c2(y), int(y)]))\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=num_cores)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform, target_transform = coarser)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_cores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c0ea53-ba3c-4e1e-b687-d361ce7c7c6b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## NA_Layer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a52da67f-ad0f-4bf4-a9dc-9be1bc0a4441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"class NA_Layer2(ABC, nn.Module):\\n    def __init__(self):\\n        super().__init__()\\n\\n    def forward(self, x):\\n        yf = self.layer_f(x[0, :])\\n        yi = self.layer_f(x[1, :]) + self.layer_i(x[0, :])\\n\\n        return torch.stack((yf, yi))\\n\\n    def infinitesimal_gradient(self):\\n        self.layer_i.weight.grad = self.layer_f.weight.grad\\n        self.layer_f.weight.grad = None\\n\\n        if bias:\\n            self.layer_i.bias.grad = self.layer_f.bias.grad\\n            self.layer_f.bias.grad = None\\n\\nclass NA_Linear2(NA_Layer2):\\n    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\\n\\n        super().__init__()\\n        self.bias = bias\\n        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\\n        self.layer_i = nn.Linear(in_features, out_features, bias, device, dtype)\\n\\nclass NA_Conv2d2(NA_Layer2):\\n\\n    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \\n                padding_mode='zeros', device=None, dtype=None):\\n\\n        super().__init__()\\n        self.bias = bias\\n        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \\n                padding_mode, device, dtype)\\n        self.layer_i = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \\n                padding_mode, device, dtype)\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"class NA_Layer2(ABC, nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi = self.layer_f(x[1, :]) + self.layer_i(x[0, :])\n",
    "\n",
    "        return torch.stack((yf, yi))\n",
    "\n",
    "    def infinitesimal_gradient(self):\n",
    "        self.layer_i.weight.grad = self.layer_f.weight.grad\n",
    "        self.layer_f.weight.grad = None\n",
    "\n",
    "        if bias:\n",
    "            self.layer_i.bias.grad = self.layer_f.bias.grad\n",
    "            self.layer_f.bias.grad = None\n",
    "\n",
    "class NA_Linear2(NA_Layer2):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "\n",
    "class NA_Conv2d2(NA_Layer2):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                padding_mode='zeros', device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e30205-5405-4cd6-9c8d-4dfc2b1fc36e",
   "metadata": {},
   "source": [
    "## NA_Layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "773740a6-edb6-4c6c-b808-ae622e9a2653",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NA_Layer(ABC, nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class NA_combiner3(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi1 = self.layer_f(x[1, :]) + self.layer_i1(x[0, :])\n",
    "        yi2 = self.layer_f(x[2, :]) + self.layer_i1(x[1, :]) + self.layer_i2(x[0, :])\n",
    "\n",
    "        return torch.stack((yf, yi1, yi2))\n",
    "\n",
    "    def infinitesimal_gradient(self, i):\n",
    "        if i == 1:\n",
    "            self.layer_i1.weight.grad = self.layer_f.weight.grad\n",
    "            self.layer_f.weight.grad = None\n",
    "    \n",
    "            if self.bias:\n",
    "                self.layer_i1.bias.grad = self.layer_f.bias.grad\n",
    "                self.layer_f.bias.grad = None\n",
    "        \n",
    "        elif i == 2:\n",
    "            self.layer_i2.weight.grad = self.layer_f.weight.grad\n",
    "            self.layer_i1.weight.grad = None\n",
    "            self.layer_f.weight.grad = None\n",
    "    \n",
    "            if self.bias:\n",
    "                self.layer_i2.bias.grad = self.layer_f.bias.grad\n",
    "                self.layer_i1.bias.grad = None\n",
    "                self.layer_f.bias.grad = None\n",
    "            \n",
    "class NA_separate3(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        yf = self.layer_f(x[0, :])\n",
    "        yi1 = self.layer_i1(x[1, :])\n",
    "        yi2 = self.layer_i2(x[2, :])\n",
    "\n",
    "        return torch.stack((yf, yi1, yi2))\n",
    "\n",
    "class NA_independent(NA_Layer):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        for i in np.arange(x.size(0)):\n",
    "            y.append(self.layer(x[i, :]))\n",
    "\n",
    "        return torch.stack(y)\n",
    "\n",
    "class NA_Linear3(NA_combiner3):\n",
    "    def __init__(self, in_features: int, out_features: int, bias: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i1 = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "        self.layer_i2 = nn.Linear(in_features, out_features, bias, device, dtype)\n",
    "\n",
    "class NA_Conv2d3(NA_combiner3):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
    "                padding_mode='zeros', device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bias = bias\n",
    "        self.layer_f = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "        self.layer_i2 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, \n",
    "                padding_mode, device, dtype)\n",
    "\n",
    "class NA_BatchNorm2d3(NA_separate3):\n",
    "\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5, momentum: float = 0.1, affine: bool = True,\n",
    "                 track_running_stats: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layer_f = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i1 = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i2 = nn.BatchNorm2d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "\n",
    "class NA_BatchNorm1d3(NA_separate3):\n",
    "\n",
    "    def __init__(self, num_features: int, eps: float = 1e-5, momentum: float = 0.1, affine: bool = True,\n",
    "                 track_running_stats: bool = True, device=None, dtype=None):\n",
    "\n",
    "        super().__init__()\n",
    "        self.layer_f = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i1 = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "        self.layer_i2 = nn.BatchNorm1d(num_features, eps, momentum, affine, track_running_stats, device, dtype)\n",
    "\n",
    "class NA_MaxPool2d(NA_independent):\n",
    "\n",
    "    def __init__(self, kernel_size, stride = None, padding = 0, dilation = 1, return_indices = False, ceil_mode = False):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.layer = nn.MaxPool2d(kernel_size, stride, padding, dilation, return_indices, ceil_mode)\n",
    "\n",
    "class NA_Dropout(NA_independent):\n",
    "\n",
    "     def __init__(self, p: float = 0.5, inplace: bool = False):\n",
    "         \n",
    "         super().__init__()\n",
    "         self.layer = nn.Dropout(p, inplace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bee2f1c-fe02-4497-8102-4fbbcdceff28",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NA_BCNN3(nn.Module):\n",
    "    def __init__(self, learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, \n",
    "                 every_print = 512, training_size = 50000):\n",
    "\n",
    "        super().__init__()\n",
    "        self.trainloader = trainloader\n",
    "        self.testloader = testloader\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.activation = F.relu\n",
    "        self.class_levels = 3\n",
    "        self.num_c_1 = num_class_c1\n",
    "        self.num_c_2 = num_class_c2\n",
    "        self.num_c_3 = num_class_c3\n",
    "        self.epochs = epochs\n",
    "        self.labels_c_1 = labels_c_1\n",
    "        self.labels_c_2 = labels_c_2\n",
    "        self.labels_c_3 = labels_c_3\n",
    "        self.every_print = every_print - 1 # assumed power of 2, -1 to make the mask\n",
    "        self.track_size = int( training_size / batch_size / every_print ) \n",
    "\n",
    "        self.layer1  = NA_Conv2d3(3, 64, (3,3), padding = 'same')\n",
    "        self.layer2  = NA_BatchNorm2d3(64)\n",
    "        self.layer3  = NA_Conv2d3(64, 64, (3,3), padding = 'same')\n",
    "        self.layer4  = NA_BatchNorm2d3(64)\n",
    "        self.layer5  = NA_MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layer6  = NA_Conv2d3(64, 128, (3,3), padding = 'same')\n",
    "        self.layer7  = NA_BatchNorm2d3(128)\n",
    "        self.layer8  = NA_Conv2d3(128, 128, (3,3), padding = 'same')\n",
    "        self.layer9  = NA_BatchNorm2d3(128)\n",
    "        self.layer10 = NA_MaxPool2d((2,2), stride = (2,2))\n",
    "\n",
    "        self.layerb11 = NA_Linear3(8*8*128, 256)\n",
    "        self.layerb12 = NA_BatchNorm1d3(256)\n",
    "        self.layerb13 = NA_Dropout(0.5)\n",
    "        self.layerb14 = NA_Linear3(256, 256)\n",
    "        self.layerb15 = NA_BatchNorm1d3(256)\n",
    "        self.layerb16 = NA_Dropout(0.5)\n",
    "        self.layerb17 = nn.Linear(256, self.num_c_1)\n",
    "        self.layerb18 = nn.Linear(256, self.num_c_2)\n",
    "        self.layerb19 = nn.Linear(256, self.num_c_3)\n",
    "\n",
    "        self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[0], \n",
    "                                   momentum = self.momentum, nesterov = self.nesterov)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        #self.criterion = nn.MSE()\n",
    "\n",
    "        self.combiner_layers = [self.layer1, self.layer3, self.layer6, self.layer8,\n",
    "                                   self.layerb11, self.layerb14]\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # block 1\n",
    "        z = self.layer1(x)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer4(z)\n",
    "        z = self.layer5(z)\n",
    "\n",
    "        # block 2\n",
    "        z = self.layer6(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer7(z)\n",
    "        z = self.layer8(z)\n",
    "        z = self.activation(z)\n",
    "        z = self.layer9(z)\n",
    "        z = self.layer10(z)\n",
    "\n",
    "        # branch 1\n",
    "        b1 = torch.flatten(z, start_dim = 2)\n",
    "        b1 = self.layerb11(b1)\n",
    "        b1 = self.activation(b1)\n",
    "        b1 = self.layerb12(b1)\n",
    "        b1 = self.layerb13(b1)\n",
    "        b1 = self.layerb14(b1)\n",
    "        b1 = self.activation(b1)\n",
    "        b1 = self.layerb15(b1)\n",
    "        b1 = self.layerb16(b1)\n",
    "        b1_f = self.layerb17(b1[0, :])\n",
    "        b1_i1 = self.layerb18(b1[1, :])\n",
    "        b1_i2 = self.layerb19(b1[2, :])\n",
    "\n",
    "        return b1_f, b1_i1, b1_i2\n",
    "\n",
    "\n",
    "    def update_training_params(self, epoch):\n",
    "        \n",
    "        if epoch == 41:\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[1], \n",
    "                               momentum = self.momentum, nesterov = self.nesterov)\n",
    "        elif epoch == 51:\n",
    "            self.optimizer = optim.SGD(self.parameters(), lr = self.learning_rate[2], \n",
    "                               momentum = self.momentum, nesterov = self.nesterov)\n",
    "\n",
    "\n",
    "    def predict_and_learn(self, batch, labels):\n",
    "        self.optimizer.zero_grad()\n",
    "        predict = self(batch)\n",
    "        loss_f = self.criterion(predict[0], labels[:,0])\n",
    "        loss_i1 = self.criterion(predict[1], labels[:,1])\n",
    "        loss_i2 = self.criterion(predict[2], labels[:,2])\n",
    "\n",
    "        loss_i2.backward(retain_graph=True)\n",
    "        for l in self.combiner_layers:\n",
    "            l.infinitesimal_gradient(2)\n",
    "\n",
    "        loss_i1.backward(retain_graph=True)\n",
    "        for l in self.combiner_layers:\n",
    "            l.infinitesimal_gradient(1)\n",
    "\n",
    "        loss_f.backward()\n",
    "        \n",
    "        self.optimizer.step()\n",
    "\n",
    "        return torch.tensor([loss_f, loss_i1, loss_i2])\n",
    "\n",
    "\n",
    "    def train_model(self, verbose = False):\n",
    "        self.train()\n",
    "        \n",
    "        for epoch in np.arange(self.epochs):\n",
    "            self.update_training_params(epoch)\n",
    "\n",
    "            if verbose:\n",
    "                running_loss = torch.zeros(self.class_levels)\n",
    "            \n",
    "            for iter, (batch, labels) in enumerate(self.trainloader):\n",
    "                loss = self.predict_and_learn(torch.stack((batch, torch.zeros_like(batch), torch.zeros_like(batch))), labels)\n",
    "\n",
    "                if verbose:\n",
    "                    running_loss += (loss - running_loss) / (iter+1)\n",
    "                    if (iter + 1) & self.every_print == 0:\n",
    "                        print(f'[{epoch + 1}] loss_f : {running_loss[0] :.3f}')\n",
    "                        print(f'[{epoch + 1}] loss_i1: {running_loss_[1] :.3f}')\n",
    "                        print(f'[{epoch + 1}] loss_i2: {running_loss_[2] :.3f}')\n",
    "                        for i in np.arange(self.class_levels):\n",
    "                            running_loss[i] = 0.0\n",
    "\n",
    "    \n",
    "    def train_track(self, filename = None):\n",
    "        self.train()\n",
    "        \n",
    "        self.loss_track = torch.zeros(self.epochs * self.track_size, self.class_levels)\n",
    "        self.accuracy_track = torch.zeros(self.epochs * self.track_size, self.class_levels)\n",
    "        num_push = 0\n",
    "        \n",
    "        for epoch in np.arange(self.epochs):\n",
    "\n",
    "            self.update_training_params(epoch)\n",
    "\n",
    "            running_loss = torch.zeros(self.class_levels)\n",
    "            \n",
    "            for iter, (batch, labels) in enumerate(self.trainloader):\n",
    "                loss = self.predict_and_learn(torch.stack((batch, torch.zeros_like(batch), torch.zeros_like(batch))), labels)\n",
    "\n",
    "                running_loss += (loss - running_loss) / (iter+1)\n",
    "                if (iter + 1) & self.every_print == 0:\n",
    "                    self.loss_track[num_push, :] = running_loss\n",
    "                    self.accuracy_track[num_push, :] = self.test(mode = \"train\")\n",
    "                    num_push += 1\n",
    "                    for i in np.arange(self.class_levels):\n",
    "                            running_loss[i] = 0.0\n",
    "\n",
    "        self.plot_training_loss(filename+\"_train_loss.pdf\")\n",
    "        self.plot_test_accuracy(filename+\"_test_accuracy_.pdf\")\n",
    "\n",
    "\n",
    "    def initialize_memory(self):\n",
    "        self.correct_c1_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_pred = torch.zeros_like(self.correct_c1_pred)\n",
    "        \n",
    "        self.correct_c2_pred = torch.zeros(self.num_c_2)\n",
    "        self.total_c2_pred = torch.zeros_like(self.correct_c2_pred)\n",
    "        \n",
    "        self.correct_c3_pred = torch.zeros(self.num_c_3)\n",
    "        self.total_c3_pred = torch.zeros_like(self.correct_c3_pred)\n",
    "\n",
    "        self.correct_c1_vs_c2_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_vs_c2_pred = torch.zeros_like(self.correct_c1_vs_c2_pred)\n",
    "\n",
    "        self.correct_c2_vs_c3_pred = torch.zeros(self.num_c_2)\n",
    "        self.total_c2_vs_c3_pred = torch.zeros_like(self.correct_c2_vs_c3_pred)\n",
    "\n",
    "        self.correct_c1_vs_c3_pred = torch.zeros(self.num_c_1)\n",
    "        self.total_c1_vs_c3_pred = torch.zeros_like(self.correct_c1_vs_c3_pred)\n",
    "\n",
    "\n",
    "    def collect_test_performance(self):\n",
    "        with torch.no_grad():\n",
    "            for images, labels in self.testloader:\n",
    "                predictions = self(torch.stack((images, torch.zeros_like(images), torch.zeros_like(images))))\n",
    "                predicted = torch.zeros(batch_size, self.class_levels, dtype=torch.long)\n",
    "                _, predicted[:,0] = torch.max(predictions[0], 1)\n",
    "                _, predicted[:,1] = torch.max(predictions[1], 1)\n",
    "                _, predicted[:,2] = torch.max(predictions[2], 1)\n",
    "\n",
    "                for i in np.arange(batch_size):\n",
    "                    if labels[i,0] == predicted[i,0]:\n",
    "                        self.correct_c1_pred[labels[i,0]] += 1\n",
    "                        \n",
    "                    if labels[i,1] == predicted[i,1]:\n",
    "                        self.correct_c2_pred[labels[i,1]] += 1\n",
    "\n",
    "                    if labels[i,2] == predicted[i,2]:\n",
    "                        self.correct_c3_pred[labels[i,2]] += 1\n",
    "\n",
    "                    if predicted[i,1] == c3_to_c2(predicted[i,2]):\n",
    "                        self.correct_c2_vs_c3_pred[predicted[i,1]] += 1\n",
    "\n",
    "                    if predicted[i,0] == c3_to_c1(predicted[i,2]):\n",
    "                        self.correct_c1_vs_c3_pred[predicted[i,0]] += 1\n",
    "\n",
    "                    if predicted[i,0] == c2_to_c1(predicted[i,1]):\n",
    "                        self.correct_c1_vs_c2_pred[predicted[i,0]] += 1\n",
    "                        \n",
    "                    self.total_c1_pred[labels[i,0]] += 1\n",
    "                    self.total_c2_pred[labels[i,1]] += 1\n",
    "                    self.total_c3_pred[labels[i,2]] += 1\n",
    "                    self.total_c1_vs_c3_pred[predicted[i,0]] += 1\n",
    "                    self.total_c1_vs_c2_pred[predicted[i,0]] += 1\n",
    "                    self.total_c2_vs_c3_pred[predicted[i,1]] += 1\n",
    "\n",
    "    def print_test_results(self):\n",
    "        # print accuracy for each class\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1 = 100 * float(self.correct_c1_pred[i]) / self.total_c1_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_1[i]:5s}: {accuracy_c1:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2 = 100 * float(self.correct_c2_pred[i]) / self.total_c2_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_2[i]:5s}: {accuracy_c2:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_3):\n",
    "            accuracy_c3 = 100 * float(self.correct_c3_pred[i]) / self.total_c3_pred[i]\n",
    "            print(f'Accuracy for class {self.labels_c_3[i]:5s}: {accuracy_c3:.2f} %')\n",
    "            \n",
    "        # print accuracy for the whole dataset\n",
    "        print(\"\")\n",
    "        print(f'Accuracy on c1: {100 * self.correct_c1_pred.sum() // self.total_c1_pred.sum()} %')\n",
    "        print(f'Accuracy on c2: {100 * self.correct_c2_pred.sum() // self.total_c2_pred.sum()} %')\n",
    "        print(f'Accuracy on c3: {100 * self.correct_c3_pred.sum() // self.total_c3_pred.sum()} %')\n",
    "\n",
    "        # print cross classes accuracy (tree)\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1_c2 = 100 * float(self.correct_c1_vs_c2_pred[i]) / self.total_c1_vs_c2_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_1[i]:5s} vs c2: {accuracy_c1_c2:.2f} %')\n",
    "        \n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2_c3 = 100 * float(self.correct_c2_vs_c3_pred[i]) / self.total_c2_vs_c3_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_2[i]:5s} vs c3: {accuracy_c2_c3:.2f} %')\n",
    "\n",
    "        print(\"\")\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1_c3 = 100 * float(self.correct_c1_vs_c3_pred[i]) / self.total_c1_vs_c3_pred[i]\n",
    "            print(f'Cross-accuracy {self.labels_c_1[i]:5s} vs c3: {accuracy_c1_c3:.2f} %')\n",
    "\n",
    "\n",
    "    def barplot(self, x, accuracy, labels, title):\n",
    "        plt.bar(x, accuracy, tick_label = labels)\n",
    "        plt.xlabel(\"Classes\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.title(title)\n",
    "        plt.show();\n",
    "\n",
    "    def plot_test_results(self):\n",
    "        # accuracy for each class\n",
    "        accuracy_c1 = torch.empty(self.num_c_1)\n",
    "        for i in np.arange(self.num_c_1):\n",
    "            accuracy_c1[i] = float(self.correct_c1_pred[i]) / self.total_c1_pred[i]\n",
    "        self.barplot(np.arange(self.num_c_1), accuracy_c1, self.labels_c_1, \"Accuracy on the first level\")\n",
    "\n",
    "        accuracy_c2 = torch.empty(self.num_c_2 + 1)\n",
    "        for i in np.arange(self.num_c_2):\n",
    "            accuracy_c2[i] = float(self.correct_c2_pred[i]) / self.total_c2_pred[i]\n",
    "        accuracy_c2[self.num_c_2] = self.correct_c2_pred.sum() / self.total_c2_pred.sum()\n",
    "        self.barplot(np.arange(self.num_c_2 + 1), accuracy_c2, (*self.labels_c_2, 'overall'), \"Accuracy on the second level\")\n",
    "\n",
    "        accuracy_c3 = torch.empty(self.num_c_3 + 1)\n",
    "        for i in np.arange(self.num_c_3):\n",
    "            accuracy_c3[i] = float(self.correct_c3_pred[i]) / self.total_c3_pred[i]\n",
    "        accuracy_c3[self.num_c_3] = self.correct_c3_pred.sum() / self.total_c3_pred.sum()\n",
    "        self.barplot(np.arange(self.num_c_3 + 1), accuracy_c3, (*self.labels_c_3, 'overall'), \"Accuracy on the third level\")\n",
    "\n",
    "    \n",
    "    def test(self, mode = \"print\"):\n",
    "        self.initialize_memory()\n",
    "        self.eval()\n",
    "\n",
    "        self.collect_test_performance()\n",
    "\n",
    "        match mode:\n",
    "            case \"plot\":\n",
    "                self.plot_test_results()\n",
    "            case \"print\":\n",
    "                self.print_test_results()\n",
    "            case \"train\":\n",
    "                accuracy_c1 = self.correct_c1_pred.sum() / self.total_c1_pred.sum()\n",
    "                accuracy_c2 = self.correct_c2_pred.sum() / self.total_c2_pred.sum()\n",
    "                accuracy_c3 = self.correct_c3_pred.sum() / self.total_c3_pred.sum()\n",
    "\n",
    "                self.train()\n",
    "\n",
    "                return torch.tensor([accuracy_c1, accuracy_c2, accuracy_c3])\n",
    "            case _:\n",
    "                raise AttributeError(\"Test mode not available\")\n",
    "        \n",
    "    \n",
    "    def plot_training_loss(self, filename = None):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 0].numpy(), label = \"First level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 1].numpy(), label = \"Second level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.loss_track.size(0)), self.loss_track[:, 2].numpy(), label = \"Third level\")\n",
    "        plt.title(\"Training loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Error\")\n",
    "        plt.xticks(np.linspace(1, self.epochs, self.epochs)[0::2])\n",
    "        plt.legend()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show();\n",
    "\n",
    "    def plot_test_accuracy(self, filename = None):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 0].numpy(), label = \"First level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 1].numpy(), label = \"Second level\")\n",
    "        plt.plot(np.linspace(1, self.epochs, self.accuracy_track.size(0)), self.accuracy_track[:, 2].numpy(), label = \"Third level\")\n",
    "        plt.title(\"Test accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xticks(np.linspace(1, self.epochs, self.epochs)[0::2])\n",
    "        plt.legend()\n",
    "        if filename is not None:\n",
    "            plt.savefig(filename, bbox_inches='tight')\n",
    "        plt.show();\n",
    "\n",
    "    def save_model(self, path):\n",
    "        torch.save(self.state_dict(), path)\n",
    "\n",
    "    def load_model(self, path):\n",
    "        self.load_state_dict(torch.load(path))\n",
    "        self.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb179173-4f1e-4e66-8f7e-8f2d51521a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [3e-3, 5e-4, 1e-4]\n",
    "momentum = 0.9\n",
    "nesterov = True\n",
    "epochs = 60\n",
    "num_class_c1 = 2\n",
    "num_class_c2 = 7\n",
    "num_class_c3 = 10\n",
    "every_print = 32\n",
    "\n",
    "#--- coarse 1 classes ---\n",
    "labels_c_1 = ('transport', 'animal')\n",
    "#--- coarse 2 classes ---\n",
    "labels_c_2 = ('sky', 'water', 'road', 'bird', 'reptile', 'pet', 'medium')\n",
    "#--- fine classes ---\n",
    "labels_c_3 = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8cb713-b124-4ccd-9748-467b99c72839",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Terminator()\n",
    "cnn = NA_BCNN3(learning_rate, momentum, nesterov, trainloader, testloader, \n",
    "                 epochs, num_class_c1, num_class_c2, num_class_c3, labels_c_1, labels_c_2, labels_c_3, every_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474da885-cb0e-49ab-88d2-f47d66ad64de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn.train_model(verbose = False)\n",
    "err = False\n",
    "filename = \"models/B-CNN3_CIFAR10_NA\"\n",
    "\n",
    "try:\n",
    "    cnn.train_track(filename)\n",
    "    cnn.save_model(filename+\".pt\")\n",
    "    cnn.test(mode = \"print\")\n",
    "    \n",
    "except Exception as errore:\n",
    "    err = errore\n",
    "\n",
    "if err is False:\n",
    "    bot.sendMessage(\"Programma terminato correttamente\")\n",
    "else:\n",
    "    bot.sendMessage(\"Programma NON terminato correttamente\\nTipo di errore: \"+err.__class__.__name__+\"\\nMessaggio: \"+str(err))\n",
    "    raise err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb15899-9622-450f-8a2b-c910241407ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
